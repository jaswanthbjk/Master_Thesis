%!TEX root = ../report.tex

\begin{document}
\justifying
    \begin{abstract}
        Autonomous Vehicles (\acrshort{av}) is one of the potential solutions to improve on-road safety. But \acrshort{av} are prone to making mistakes that might be catastrophic. These errors are the results of the perception models being confronted with unknown data or a novel event as these vehicles are deployed in open-ended environments. The unknown or novel data is generally referred to as \acrlong{ood} (\acrshort{ood}) data. A method to detect this \acrshort{ood} samples is very important for the safe deployment of the \acrshort{av}.
        
        This work reviews and investigates the ability and adaptability of various \acrshort{ood} detection methods in the task of object detection. Our approach is to regress a novelty score for every detection made by the object detector model. The novelty score is method-dependent, it can be a probability metric, a distance metric, or a descriptive statistical value.
        
        We explored the abilities of Max Softmax, ODIN, and Uncertainty-based OOD detectors in detecting unknown objects and unknown environments. Since there are no established methods to evaluate the \acrshort{ood} detection in object detection. We proposed a new dataset called \acrlong{ood} for Object Detection ($OD^2$) dataset for benchmarking. The dataset is made up of: \acrshort{bdd} dataset which acts as an \acrlong{id} (\acrshort{id}) dataset and is used for training our object detector, \acrlong{idd} (IDD) dataset which acts as \acrshort{ood} dataset. We also used artificial climate images generated by ClimateGAN to test out-of-domain performance. 
        
        We found that the Bayesian model of SSD300 has outperformed the Sub-Ensemble model and vanilla SSD300 by 3.37\% and 4.1\% respectively in terms of object detection performance measured using mean average precision. But these methods struggled in performing \acrshort{ood} detection by producing almost similar \acrshort{auroc} scores compared to Max Softmax, ODIN, and uncertainty methods with probability, entropy, and box deviation as metrics. But Sub-Ensembles outperformed the Bayesian model by 11\% in terms of \acrshort{auroc} scores while using the least number of parameters for uncertainty extraction purposes. 
    \end{abstract}
\end{document}
